{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-5 ファインチューニングの実装\n",
    "## ファインチューニング\n",
    "ファインチューニング（fine tuning）は，学習済みモデルをベースに出力層などを変更したモデルを構築し，自前のデータでニューラルネットワーク・モデルの結合パラメータを学習させる手法．\n",
    "転移学習とは異なり前奏のパラメータを再学習するが，入力層に近い部分の学習率は小さくまたは0に設定し，出力層付近の学習率は大きく設定する．\n",
    "\n",
    "## フォルダの準備と事前準備\n",
    "GPU 環境でも make_folders_and_data_downloads.ipynb を実行して 1-3 と同様な環境を構築する．\n",
    "\n",
    "## Dataset と DataLoader を作成\n",
    "1−3 で作成した ImageTransform，make_datapath_list，HymenopteraDataset を utils フォルダ内の dataloader_image_classification.py から読み込む．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import glob\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torchvision import models, transforms\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/hymenoptera_data/train/**/*.jpg\n",
      "./data/hymenoptera_data/val/**/*.jpg\n"
     ]
    }
   ],
   "source": [
    "from utils.dataloader_image_classification import ImageTransform, HymenopteraDataset, make_datapath_list\n",
    "\n",
    "# アリとハチの画像へのファイルパスのリストを作成する\n",
    "train_list = make_datapath_list(phase=\"train\")\n",
    "val_list = make_datapath_list(phase=\"val\")\n",
    "\n",
    "# Dataset の作成\n",
    "size = 224\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "train_dataset = HymenopteraDataset(file_list=train_list, transform=ImageTransform(size, mean, std), phase=\"train\")\n",
    "val_dataset = HymenopteraDataset(file_list=val_list, transform=ImageTransform(size, mean, std), phase=\"val\")\n",
    "\n",
    "# DataLoader の作成\n",
    "batch_size = 32\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 辞書にまとめる\n",
    "dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ネットワークモデルを作成\n",
    "1-3節と同じように出力層を変更する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ネットワーク設定完了：学習済みの重みをロードし，訓練モードにセットしました\n"
     ]
    }
   ],
   "source": [
    "use_pretrained = True\n",
    "net = models.vgg16(pretrained=use_pretrained)\n",
    "\n",
    "net.classifier[6] = nn.Linear(in_features=4096, out_features=2)\n",
    "net.train()\n",
    "\n",
    "print(\"ネットワーク設定完了：学習済みの重みをロードし，訓練モードにセットしました\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 損失関数を定義\n",
    "これも1-3節と同様にクロスエントロピー誤差関数を用いる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最適化手法を設定\n",
    "転移学習とは異なり全層のパラメータを学習できるように optimizer を設定する．\n",
    "各層ごとに学習率を変えられるようにパラメータを設定し，それぞれについて異なる学習率を適用する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params_to_update_1 に格納： features.0.weight\n",
      "params_to_update_1 に格納： features.0.bias\n",
      "params_to_update_1 に格納： features.2.weight\n",
      "params_to_update_1 に格納： features.2.bias\n",
      "params_to_update_1 に格納： features.5.weight\n",
      "params_to_update_1 に格納： features.5.bias\n",
      "params_to_update_1 に格納： features.7.weight\n",
      "params_to_update_1 に格納： features.7.bias\n",
      "params_to_update_1 に格納： features.10.weight\n",
      "params_to_update_1 に格納： features.10.bias\n",
      "params_to_update_1 に格納： features.12.weight\n",
      "params_to_update_1 に格納： features.12.bias\n",
      "params_to_update_1 に格納： features.14.weight\n",
      "params_to_update_1 に格納： features.14.bias\n",
      "params_to_update_1 に格納： features.17.weight\n",
      "params_to_update_1 に格納： features.17.bias\n",
      "params_to_update_1 に格納： features.19.weight\n",
      "params_to_update_1 に格納： features.19.bias\n",
      "params_to_update_1 に格納： features.21.weight\n",
      "params_to_update_1 に格納： features.21.bias\n",
      "params_to_update_1 に格納： features.24.weight\n",
      "params_to_update_1 に格納： features.24.bias\n",
      "params_to_update_1 に格納： features.26.weight\n",
      "params_to_update_1 に格納： features.26.bias\n",
      "params_to_update_1 に格納： features.28.weight\n",
      "params_to_update_1 に格納： features.28.bias\n",
      "params_to_update_2 に格納： classifier.0.weight\n",
      "params_to_update_2 に格納： classifier.0.bias\n",
      "params_to_update_2 に格納： classifier.3.weight\n",
      "params_to_update_2 に格納： classifier.3.bias\n",
      "params_to_update_3 に格納： classifier.6.weight\n",
      "params_to_update_3 に格納： classifier.6.bias\n"
     ]
    }
   ],
   "source": [
    "# ファインチューニングで学習させるパラメータを3つのグループに分ける\n",
    "params_to_update_1 = []\n",
    "params_to_update_2 = []\n",
    "params_to_update_3 = []\n",
    "\n",
    "# 学習させる層のパラメータ名を指定\n",
    "update_param_names_1 = [\"features\"]\n",
    "update_param_names_2 = [\"classifier.0.weight\", \"classifier.0.bias\", \"classifier.3.weight\", \"classifier.3.bias\"]\n",
    "update_param_names_3 = [\"classifier.6.weight\", \"classifier.6.bias\"]\n",
    "\n",
    "# パラメータごとに各リストに格納する\n",
    "for name, param in net.named_parameters():\n",
    "    if update_param_names_1[0] in name:\n",
    "        param.requires_grad = True\n",
    "        params_to_update_1.append(param)\n",
    "        print(\"params_to_update_1 に格納：\", name)\n",
    "        \n",
    "    elif name in update_param_names_2:\n",
    "        param.requires_grad = True\n",
    "        params_to_update_2.append(param)\n",
    "        print(\"params_to_update_2 に格納：\", name)\n",
    "        \n",
    "    elif name in update_param_names_3:\n",
    "        param.requires_grad = True\n",
    "        params_to_update_3.append(param)\n",
    "        print(\"params_to_update_3 に格納：\", name)\n",
    "        \n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "        print(\"勾配計算なし，学習しない ：\", name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上で作成した各層のグループに対して次のように異なる学習率を設定する．ここでも Momentum SGD を用いる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最適化手法の設定\n",
    "optimizer = optim.SGD([\n",
    "    {\"params\": params_to_update_1, \"lr\": 1e-4},\n",
    "    {\"params\": params_to_update_2, \"lr\": 1e-4},\n",
    "    {\"params\": params_to_update_3, \"lr\": 1e-3}\n",
    "], momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習・検証を実施\n",
    "基本的には1-3節と同じコードを用いる．ここから先は GPU を用いて学習するため，その設定を行うコードを挿入する．  \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") とすることで GPU が使用可能であれば GPU を，それ以外は CPU を使うようにデバイスを設定する．こうしてデバイスを指定したのち， to(device) とすることで GPU でも CPU でもコードを実行できるようになる．\n",
    "また，イテレーションごとのニューラルネットワークの順伝播および誤差関数の計算手法がある程度一定であれば，torch.backends.cudnn.benchmark = True とすることで GPU の計算を高速化できる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用デバイス： cuda:0\n"
     ]
    }
   ],
   "source": [
    "def trein_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
    "    # GPU が使えるか確認\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"使用デバイス：\", device)\n",
    "    \n",
    "    # ネットワークを GPU 上へ移動する\n",
    "    net.to(device)\n",
    "    \n",
    "    # ネットワークがある程度固定であれば高速化できる\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    # epoch 数だけループ\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch + 1, num_epochs))\n",
    "        print(\"-----------\")\n",
    "        \n",
    "        # 学習と検証のループ\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                net.train()\n",
    "            if phase == \"val\":\n",
    "                net.eval()\n",
    "                \n",
    "            epoch_loss = 0.0      # epoch の損失和\n",
    "            epoch_cerrects = 0  # epoch の正解数\n",
    "            \n",
    "            # 未学習時の検証性能を確かめるため epoch = 0 の訓練は行わない\n",
    "            if (epoch == 0) and (phase == \"train\"):\n",
    "                continue\n",
    "            \n",
    "            # データローダからミニバッチを取り出す\n",
    "            for inputs, labels in tqdm(dataloaders_dict[phase]):\n",
    "                # GPU が使えるなら GPU にデータを送る\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                # optimizer の初期化\n",
    "                optimizer.zero_grad()\n",
    "            \n",
    "                # 順伝播の計算\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    outputs = net(inputs)\n",
    "                    loss = criterion(outputs, labels)  # 損失の計算\n",
    "                    _, preds = torch.max(outputs, 1)   # ラベルの予測\n",
    "                \n",
    "                    # 訓練時は逆伝播も計算\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                    \n",
    "                    # イテレーション結果の計算\n",
    "                    epoch_loss += loss.item() * inputs.size(0)\n",
    "                    epoch_cerrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            # epoch ごとの loss と正解率を表示\n",
    "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
    "            epoch_acc = epoch_cerrects.double() / len(dataloaders_dict[phase].dataset)\n",
    "            print(\"{} Loss: {:.4f} Acc: {:.4f}\".format(phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "\n",
    "# 1回だけ学習と検証を行う\n",
    "num_epochs = 2\n",
    "trein_model(net, dataloaders_dict, criterion, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ファインチューニングによってうまく分類できるようになっていることが確認できる．\n",
    "また，GPU を使用しているため計算もかなり高速化されている．\n",
    "\n",
    "## 学習したネットワークを保存・ロード\n",
    "学習したモデルを格納した変数 net に対して .state_dict() でパラメータを辞書型変数に書き出し，torch.save() で保存先のファイルパスを指定して保存する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"./weights_fine_tuning.pth\"\n",
    "torch.save(net.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ロードする際は torch.load() で辞書型のオブジェクトとしてロードし，ネットワークに load_state_dict() で格納する．GPU で保存したファイルを CPU 上に展開するには map_location を使う必要がある．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = \"./weights_fine_tuning.pth\"\n",
    "load_weights = torch.load(load_path)\n",
    "net.load_state_dict(load_weights)\n",
    "\n",
    "# GPU 上で保存したモデルを CPU　上に展開する場合\n",
    "load_weights = torch.load(load_path, map_location={\"cuda:0\", \"cpu\"})\n",
    "net.load_state_dict(load_weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
