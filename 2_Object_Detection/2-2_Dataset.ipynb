{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-2 Dataset の実装\n",
    "ここでは SSD に限らず他の物体検出手法でも汎用的に使える Dataset クラスを実装する\n",
    "\n",
    "## PyTorch によるディープラーニング実装の流れのおさらい\n",
    "1-2節参照\n",
    "\n",
    "## フォルダの準備\n",
    "make_folders_and_data_downloads.ipynb を実行してフォルダの作成とデータセットのダウンロードを行う．\n",
    "\n",
    "## 事前準備\n",
    "OpenCV をインストールしておく．\n",
    "```bash\n",
    "$ pip install opencv-python\n",
    "```\n",
    "\n",
    "### 画像データ・アノテーションデータへのファイルパスのリストを作成\n",
    "物体検出ではデータセットに正解のバウンディングボックスやラベルの情報といった，アノテーションデータが含まれる．\n",
    "そのため，前処理や訓練時のデータオーギュメンテーションでは，バウンディングボックスの情報も合わせて変更する必要がある点に留意する．  \n",
    "まずは画像データとアノテーションデータへのファイルパスのリストを作成する．\n",
    "VOC2012 データセットでは訓練データと検証データがフォルダ分けされておらず，train.txt と val.txt にそれぞれ訓練用と検証用のファイル id が記載されているため，それをもとに画像とアノテーションのファイルパスのリストを作成する必要がある．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# パッケージのimport\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "# XMLをファイルやテキストから読み込んだり、加工したり、保存したりするためのライブラリ\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datapath_list(rootpath):\n",
    "    \"\"\"\n",
    "    データへのパスを格納したリストを作成\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rootpath: str\n",
    "        データフォルダへのパス\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    ret: train_img_list, train_anno_list, val_img_list, val_anno_list\n",
    "        データへのパスを格納したリスト\n",
    "    \"\"\"\n",
    "    \n",
    "    # 画像ファイルとアノテーションファイルへのパスのテンプレートを作成\n",
    "    imgpath_template = osp.join(rootpath, 'JPEGImages', '%s.jpg')\n",
    "    annopath_template = osp.join(rootpath, 'Annotations', '%s.xml')\n",
    "    \n",
    "    # 訓練と検証についてそれぞれのファイル名を取得する\n",
    "    train_id_names = osp.join(rootpath, 'ImageSets/Main/train.txt')\n",
    "    val_id_names = osp.join(rootpath, 'ImageSets/Main/val.txt')\n",
    "    \n",
    "    # 訓練データの画像ファイルとアノテーションファイルへのパスリストを作成\n",
    "    train_img_list = list()\n",
    "    train_anno_list = list()\n",
    "    \n",
    "    for line in open(train_id_names):\n",
    "        file_id = line.strip()\n",
    "        img_path = (imgpath_template % file_id)\n",
    "        anno_path = (annopath_template % file_id)\n",
    "        train_img_list.append(img_path)\n",
    "        train_anno_list.append(anno_path)\n",
    "        \n",
    "    # 検証データの画像ファイルとアノテーションファイルへのパスリストを作成\n",
    "    val_img_list = list()\n",
    "    val_anno_list = list()\n",
    "    \n",
    "    for line in open(val_id_names):\n",
    "        file_id = line.strip()\n",
    "        img_path = (imgpath_template % file_id)\n",
    "        anno_path = (annopath_template % file_id)\n",
    "        val_img_list.append(img_path)\n",
    "        val_anno_list.append(anno_path)\n",
    "    \n",
    "    return train_img_list, train_anno_list, val_img_list, val_anno_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/VOCdevkit/VOC2012/JPEGImages/2008_000008.jpg\n"
     ]
    }
   ],
   "source": [
    "# 動作確認\n",
    "rootpath = \"./data/VOCdevkit/VOC2012/\"\n",
    "train_img_list, train_anno_list, val_img_list, val_anno_list = make_datapath_list(rootpath)\n",
    "print(train_img_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xml 形式のアノテーションデータをリストに変換\n",
    "アノテーションデータを xml 形式から Python のリスト形式に変換する Anno_xml2list クラスを作成する．\n",
    "作成に当たってはバウンディングボックスの座標を高さで割って正規化を行い，物体クラス名を文字列から数値に置き換える．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Anno_xml2list():\n",
    "    \"\"\"\n",
    "    各画像のアノテーションデータを画像サイズで規格化しリスト形式に変換\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    classes: list\n",
    "        VOC のクラス名を格納したリスト\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, classes):\n",
    "        self.classes = classes\n",
    "        \n",
    "    def __call__(self, xml_path, width, height):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        xml_path: str\n",
    "            xml ファイルへのパス\n",
    "        width: int\n",
    "            対象画像の幅\n",
    "        height: int\n",
    "            対象画像の高さ\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        ret: [[xmin, ymin, xmax, ymax, label_idx], ...]\n",
    "            物体のアノテーションデータを格納したリストで長さは画像内の物体数\n",
    "        \"\"\"\n",
    "        \n",
    "        # このリストに画像内のすべての物体のアノテーションを格納する\n",
    "        ret = []\n",
    "        \n",
    "        # xml ファイルの読み込み\n",
    "        xml = ET.parse(xml_path).getroot()\n",
    "        \n",
    "        # 画像内にある物体の数だけループ\n",
    "        for obj in xml.iter('object'):\n",
    "            # 検知が difficult となっているものは除外\n",
    "            difficult = int(obj.find('difficult').text)\n",
    "            if difficult == 1:\n",
    "                continue\n",
    "                \n",
    "            # 1つの物体に対するアノテーションを格納するリスト\n",
    "            bndbox = []\n",
    "            \n",
    "            name = obj.find('name').text.lower().strip() # 物体名を抽出\n",
    "            bbox = obj.find('bndbox') # バウンディングボックスの情報\n",
    "            \n",
    "            # バウンディングボックスの情報を0~1に規格化\n",
    "            pts = ['xmin', 'ymin', 'xmax', 'ymax']\n",
    "            \n",
    "            for pt in (pts):\n",
    "                # 原点を (0, 0) にする\n",
    "                cur_pixel = int(bbox.find(pt).text) - 1\n",
    "                \n",
    "                # 幅、高さで規格化\n",
    "                if pt == 'xmin' or pt == 'xmax':  # x方向のときは幅で割算\n",
    "                    cur_pixel /= width\n",
    "                else:  # y方向のときは高さで割算\n",
    "                    cur_pixel /= height\n",
    "\n",
    "                bndbox.append(cur_pixel)\n",
    "                \n",
    "            # アノテーションのクラス名のindexを取得して追加\n",
    "            label_idx = self.classes.index(name)\n",
    "            bndbox.append(label_idx)\n",
    "\n",
    "            # resに[xmin, ymin, xmax, ymax, label_ind]を足す\n",
    "            ret += [bndbox]\n",
    "\n",
    "        return np.array(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.09      ,  0.03003003,  0.998     ,  0.996997  , 18.        ],\n",
       "       [ 0.122     ,  0.56756757,  0.164     ,  0.72672673, 14.        ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 動作確認　\n",
    "voc_classes = ['aeroplane', 'bicycle', 'bird', 'boat',\n",
    "               'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "               'cow', 'diningtable', 'dog', 'horse',\n",
    "               'motorbike', 'person', 'pottedplant',\n",
    "               'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "\n",
    "transform_anno = Anno_xml2list(voc_classes)\n",
    "\n",
    "# 画像の読み込み OpenCVを使用\n",
    "ind = 1\n",
    "image_file_path = val_img_list[ind]\n",
    "img = cv2.imread(image_file_path)  # [高さ][幅][色BGR]\n",
    "height, width, channels = img.shape  # 画像のサイズを取得\n",
    "\n",
    "# アノテーションをリストで表示\n",
    "transform_anno(val_anno_list[ind], width, height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
