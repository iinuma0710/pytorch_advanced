{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-5 順伝搬関数の実装\n",
    "\n",
    "## 関数 decode を実装\n",
    "ここではあとから実装する Detect クラス内で使用する関数 decode を実装する．\n",
    "decode 関数ではデフォルトボックス$(cx_d, cy_d, w_d, h_d)$とオフセット情報 $loc = (\\Delta cx, \\Delta cy, \\Delta w, \\Delta h)$ からバウンディングボックスの座標情報 $(cx, cy, w, h)$を作成する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Function\n",
    "from math import sqrt\n",
    "from itertools import product\n",
    "from utils.network import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(loc, dbox_list):\n",
    "    \"\"\"\n",
    "    オフセット情報を用いてデフォルトボックスからバウンディングボックスに変換する\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    loc: [8372, 4]\n",
    "        SSD モデルで推論するオフセット情報\n",
    "    dbox_list: [8732, 4]\n",
    "        デフォルトボックスの情報\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    boxes : [xmin, ymin, xmax, ymax]\n",
    "        バウンディングボックスの情報\n",
    "    \"\"\"\n",
    "    \n",
    "    # オフセット情報からバウンディングボックスを求める\n",
    "    boxes = torch.cat((\n",
    "        dbox_list[:, :2] + loc[:, :2] * 0.1 * dbox_list[:, 2:],\n",
    "        dbox_list[:, 2:] * torch.exp(loc[:, 2:] * 0.2)\n",
    "    ), dim=1)\n",
    "    \n",
    "    # [xmin, ymin, xmax, ymax] の形に変形する\n",
    "    boxes[:, :2] -= boxes[:, 2:] / 2  # (xmin, ymin) の計算\n",
    "    boxes[:, 2:] += boxes[:, :2]      # (xmax, ymax) の計算\n",
    "    \n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Maximum Supression を行う関数を実装\n",
    "続いて，同じく Detector クラス内で使用する関数 nm_supression を実装する．\n",
    "Non−Muximum Supression は画像中の同じ物体に対してフィッティングした僅かに異なる複数個のバウンディングボックスについて，冗長なバウンディングボックスを削除し1つの物体に対しては1つのバウンディングボックスのみを残す処理である．\n",
    "実装としては，バウンディングボックス同士のかぶっている面積が閾値（ここでは0.45）以上である場合には同じ物体へのバウンディングボックスだとみなし，確信度の最も大きなものを残して他は削除するという操作を行う．\n",
    "\n",
    "次に示すコードにおいて，scores は確信度が一定以上の値（ここでは0.01）となったデフォルトボックスに対する確信度である．\n",
    "そのテンソルサイズは確信度閾値を超えたデフォルトボックスの数と同じになる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nm_surpression(boxes, scores, overlap=0.45, top_k=200):\n",
    "    \"\"\"\n",
    "    Non-Maximum Surpression を行う関数\n",
    "    boxes のうち一定以上の overlap しているバウンディングボックスを削除\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    boxes : [確信度閾値（0.01）を超えたバウンディングボックス数, 4]\n",
    "        バウンディングボックスの情報\n",
    "    scores : [確信度閾値（0.01）を超えたバウンディングボックス数]\n",
    "        conf の情報\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    keep : リスト\n",
    "        conf の降順に NMS を通過した index が格納される\n",
    "    count : int\n",
    "        NMS を通過したバウンディングボックスの数\n",
    "    \"\"\"\n",
    "    \n",
    "    # torch.Size([ 確信度閾値を超えたバウンディングボックス数 ])、要素は全部 0\n",
    "    keep  = scores.new(scores.size(0)).zero_().long()\n",
    "    count = 0\n",
    "    \n",
    "    # 各バウンディングボックスの面積を計算\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 2]\n",
    "    y2 = boxes[:, 3]\n",
    "    area = torch.mul(x2 - x1, y2 - y1)\n",
    "    \n",
    "    # boxes をコピーしてバウンディングボックスの IOU の計算に使う\n",
    "    tmp_x1 = boxes.new()\n",
    "    tmp_y1 = boxes.new()\n",
    "    tmp_x2 = boxes.new()\n",
    "    tmp_y2 = boxes.new()\n",
    "    tmp_w = boxes.new()\n",
    "    tmp_h = boxes.new()\n",
    "    \n",
    "    # scores を昇順にソート\n",
    "    v, idx = scores.sort(0)\n",
    "    \n",
    "    # 上位 top_k 個（200個）のバウンディングボックスのインデックスを取り出す\n",
    "    # ただし，200個ない場合もある\n",
    "    idx = idx[-top_k:]\n",
    "    \n",
    "    # idx の要素数が0でない限りループ\n",
    "    while idx.numel() > 0:\n",
    "        i = idx[-1]  # 最大の conf のインデックスを取得\n",
    "        \n",
    "        # keep の末尾に i を格納\n",
    "        # このインデックスのバウンディングボックスと大きく被っているバウンディングボックスをここから削除\n",
    "        keep[count] = i\n",
    "        count += 1\n",
    "        \n",
    "        # idx の要素を人るずつ減らし，残り1個になったらループを抜ける\n",
    "        if idx.size(0) == 1:\n",
    "            break\n",
    "        idx = idx[:-1]\n",
    "        \n",
    "        # ----------------------------------------------------------------------------------------------\n",
    "        # これから keep に格納したバウンディングボックスと被りの大きいバウンディングボックスを抽出し除去\n",
    "        # ----------------------------------------------------------------------------------------------\n",
    "        \n",
    "        # i までのバウンディングボックスを out に指定した変数として保存\n",
    "        torch.index_select(x1, 0, idx, out=tmp_x1)\n",
    "        torch.index_select(y1, 0, idx, out=tmp_y1)\n",
    "        torch.index_select(x2, 0, idx, out=tmp_x2)\n",
    "        torch.index_select(y2, 0, idx, out=tmp_y2)\n",
    "        \n",
    "        # 全てのバウンディングボックスについて，index が i のバウンディングボックスの範囲に限定\n",
    "        tmp_x1 = torch.clamp(tmp_x1, min=x1[i])\n",
    "        tmp_y1 = torch.clamp(tmp_y1, min=y1[i])\n",
    "        tmp_x2 = torch.clamp(tmp_x2, max=x2[i])\n",
    "        tmp_y2 = torch.clamp(tmp_y2, max=y2[i])\n",
    "        \n",
    "        # w と h のテンソルサイズを index を1つ減らした大きさにする\n",
    "        tmp_w.resize_as_(tmp_x2)\n",
    "        tmp_h.resize_as_(tmp_y2)\n",
    "        \n",
    "        # clamp した状態でバウンディングボックスの幅と高さを求める\n",
    "        tmp_w = tmp_x2 - tmp_x1\n",
    "        tmp_h = tmp_y2 - tmp_y1\n",
    "        \n",
    "        # clamp された状態での面積を求める\n",
    "        inter = tmp_w * tmp_h\n",
    "        \n",
    "        # IOU を計算\n",
    "        rem_areas = torch.index_select(area, 0, idx)  # 各バウンディングボックスの元の面積\n",
    "        union = (rem_areas - inter) + area[i]         # 2つのエリアの AND の面積\n",
    "        IOU = inter / union\n",
    "        \n",
    "        # IOU が overlap より小さい idx のみを残す\n",
    "        idx = idx[IoU.le(overlap)] # le は Less than or Equal to の処理をする演算\n",
    "        \n",
    "    return keep, count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## クラス Detect を実装\n",
    "SSD の推論時には Detect クラスを適用して $(batch\\_num, 21, 200, 5)$ のテンソルを出力する．\n",
    "テンソルの先頭はミニバッチの番号，2番目が各クラスのインデックスを示す次元，3番目が信頼度上位200個のうち何番目のバウンディングボックスか，最後がバウンディングボックスの情報 $(conf, x_{min}, y_{min}, x_{max}, y_{max})$ を表している．\n",
    "Detect クラスには次の3つの要素を入力する．\n",
    "- loc モジュールの出力 $(batch\\_num, 8732, 4)$\n",
    "- conf モジュールの出力 $(batch\\_num, 8732, 21)$\n",
    "- デフォルトボックスの情報 $(8732, 4)$\n",
    "\n",
    "このうち，conf モジュールの出力はソフトマックス関数で規格化しておく．\n",
    "実装では torch.autograd.Function クラスを継承している．\n",
    "処理の流れは以下の通り．\n",
    "1. 関数 decode を使ってデフォルトボックスとオフセット情報からバウンディングボックスに変換\n",
    "1. 確信度が閾値以上のバウンディングボックスの取り出し\n",
    "1. nm_supression 関数を適用しかぶっているバウンディングボックスを削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detect(Function):\n",
    "    def __init__(self, conf_thresh=0.01, top_k=200, nms_thresh=0.45):\n",
    "        self.softmax  = nn.Softmax(dim=-1) # conf をソフトマックス関数で正規化する\n",
    "        self.conf_thresh = conf_thresh     # conf_thresh より大きいデフォルトボックスのみ扱う\n",
    "        self.top_k = top_k                 # conf の top_k 個だけを計算に使用する\n",
    "        self.nms_thresh = nms_thresh       # nms_thresh より大きいものは同一物体へのバウンディングボックスとみなす\n",
    "        \n",
    "    def forward(self, loc_data, conf_data, dbox_list):\n",
    "        \"\"\"\n",
    "        順伝搬の計算を実行する。\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        loc_data: [batch_num,8732,4]\n",
    "            オフセット情報。\n",
    "        conf_data: [batch_num, 8732,num_classes]\n",
    "            検出の確信度。\n",
    "        dbox_list: [8732,4]\n",
    "           デフォルトボックス の情報\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        output : torch.Size([batch_num, 21, 200, 5])\n",
    "            (batch_num、クラス、conf の top200、BBox の情報)\n",
    "        \"\"\"\n",
    "\n",
    "        # 各サイズを取得\n",
    "        num_batch = loc_data.size(0) # ミニバッチのサイズ\n",
    "        num_dbox = loc_data.size(1)  # デフォルトボックスの数\n",
    "        num_classes = conf_data(2)   # クラス数\n",
    "        \n",
    "        # conf はソフトマックスを適用して正規化\n",
    "        conf_data = self.softmax(conf_data)\n",
    "        \n",
    "        # 出力の型を作成\n",
    "        output = torch.zeros(num_batch, num_classes, self.top_k, 5)\n",
    "        \n",
    "        # conf_data を [batch_num,8732,num_classes] から [batch_num, num_classes,8732] にする\n",
    "        conf_preds = conf_data.transpose(2, 1)\n",
    "        \n",
    "        # ミニバッチごとのループ\n",
    "        for i in range(num_batch):\n",
    "            # 1. loc と DBox から修正した BBox [xmin, ymin, xmax, ymax] を求める\n",
    "            decoded_boxes = decode(loc_data[i], dbox_list)\n",
    "            \n",
    "            # conf のコピーを作成\n",
    "            conf_scores = conf_preds[i].clone()\n",
    "            \n",
    "            # 画像クラスごとのループ(背景クラスの index である 0 は計算せず、index=1 から)\n",
    "            for cl in range(1, num_classes):\n",
    "                # 2.conf の閾値を超えた BBox を取り出す\n",
    "                # conf の閾値を超えているかのマスクを作成し、閾値を超えた conf のインデックスを c_mask として取得\n",
    "                c_mask = conf_scores[cl].gt(self.conf_thresh)\n",
    "                \n",
    "                # gt は Greater than のこと。gt により閾値を超えたものが 1 に、以下が 0 になる\n",
    "                # conf_scores: torch.Size([21, 8732])\n",
    "                # c_mask: torch.Size([8732])\n",
    "                \n",
    "                # scores は torch.Size([ 閾値を超えた BBox 数 ])\n",
    "                scores = conf_scores[cl][c_mask]\n",
    "                \n",
    "                # 閾値を超えた conf がない場合、つまり scores=[] のときは、何もしない\n",
    "                if scores.nelement() == 0:\n",
    "                    continue\n",
    "                    \n",
    "                # c_mask を decoded_boxes に適用できるようにサイズを変更します\n",
    "                l_mask = c_mask.unsqueeze(1).expand_as(decoded_boxes)\n",
    "                \n",
    "                # l_mask を decoded_boxes に適応します\n",
    "                # decoded_boxes[l_mask] で 1 次元になってしまうので、view で(閾値を超えた BBox 数 , 4)サイズに変形しなおす\n",
    "                boxes = decoded_boxes[l_mask].view(-1, 4)\n",
    "\n",
    "                # 3. Non-Maximum Suppression を実施し、被っている BBox を取り除く\n",
    "                ids, count = nm_suppression(boxes, scores, self.nms_thresh, self.top_k)\n",
    "                \n",
    "                # output に Non-Maximum Suppression を抜けた結果を格納\n",
    "                output[i, cl, :count] = torch.cat(( scores[ids[:count]].unsqueeze(1), boxes[ids[:count]]), 1)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSD モデルを実装\n",
    "最後に SSD モデルの順伝播を実装する．\n",
    "先にも述べたとおり，vgg，extras モジュールから source1~6 を取り出し，オフセット情報 loc と確信度 conf を取り出す．\n",
    "最終的な出力として，変数 output にオフセット情報と確信度，デフォルトボックスの情報をまとめる．\n",
    "学習時には，この変数 output が出力となる．\n",
    "推論時には Detect クラスの順伝播関数を使ってバウンディングボックスの情報を出力する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSD(nn.Module):\n",
    "    def __init__(self, phase, cfg):\n",
    "        super(SSD, self).__init__()\n",
    "        \n",
    "        self.phase = phase\n",
    "        self.cfg = cfg\n",
    "        \n",
    "        # SSD のネットワークを作る\n",
    "        self.vgg = make_vgg()\n",
    "        self.extras = make_extras()\n",
    "        self.L2Norm = L2Norm()\n",
    "        self.loc, self.conf = make_loc_conf(cfg[\"num_classes\"], cfg[\"bbox_aspect_num\"])\n",
    "        \n",
    "        # デフォルトボックスの作成\n",
    "        dbox = DBox(cfg)\n",
    "        self.dbox_list = dbox.make_dbox_list()\n",
    "        \n",
    "        # 推論時は Detect クラスを用意する\n",
    "        if phase == 'inference':\n",
    "            self.detect = Detect()\n",
    "            \n",
    "    def forward(self, x):\n",
    "        sources = list() # source1 〜 6 を格納\n",
    "        loc = list()     # loc の出力を格納\n",
    "        conf = list()    # conf の出力を格納\n",
    "        \n",
    "        # vgg の conv4_3 までを計算\n",
    "        # conv4_3 の出力を L2Norm に入力し、source1 を作成、sources に追加\n",
    "        for k in range(23):\n",
    "            x = self.vgg[k](x)\n",
    "        source1 = self.L2Norm(x)\n",
    "        sources.append(source1)\n",
    "        \n",
    "        # vgg を最後まで計算し、source2 を作成、sources に追加\n",
    "        for k in range(23, len(self.vgg)):\n",
    "            x = self.vgg[k](x)\n",
    "        sources.append(x)\n",
    "        \n",
    "        # extras の conv と ReLU を計算し，source3 〜 6 を sources に追加\n",
    "        for k, v in enumerate(self.extras):\n",
    "            x = F.relu(v(x), inplace=True)\n",
    "            if k % 2 == 1:\n",
    "                sources.append(x)\n",
    "                \n",
    "        # source1 〜 6 に、それぞれ対応する畳み込みを 1 回ずつ適用する\n",
    "        # zip で for ループの複数のリストの要素を取得\n",
    "        for (x, l, c) in zip(sources, self.loc, self.conf):\n",
    "            # permute は要素の順番を入れ替え\n",
    "            loc.append(l(x).permute(0, 2, 3, 1).configures())\n",
    "            conf.append(c(x).permute(0, 2, 3, 1).configures())\n",
    "            \n",
    "            # l(x) と c(x) で畳み込みを実行\n",
    "            # l(x) と c(x) の出力サイズは [batch_num, 4 * アスペクト比の種類数 featuremap の高さ , featuremap 幅 ]\n",
    "            # source によって、アスペクト比の種類数が異なり、面倒なので順番入れ替えて整える\n",
    "            # permute で要素の順番を入れ替え [minibatch 数 , featuremap 数 , featuremap 数 ,4 * アスペクト比の種類数 ] へ\n",
    "            # (注釈)\n",
    "            # torch.contiguous() はメモリ上で要素を連続的に配置し直す命令で，あとで view 関数を使用する\n",
    "            # この view を行うためには、対象の変数がメモリ上で連続配置されている必要がある\n",
    "            \n",
    "        # さらに loc と conf の形を変形\n",
    "        # loc のサイズは、torch.Size([batch_num, 34928])\n",
    "        # conf のサイズは torch.Size([batch_num, 183372]) になる\n",
    "        loc = torch.cat([o.view(o.size(0), -1) for o in loc], 1)\n",
    "        conf = torch.cat([o.view(o.size(0), -1) for o in conf], 1)\n",
    "        \n",
    "        # さらに loc と conf の形を整える\n",
    "        # loc のサイズは、torch.Size([batch_num, 8732, 4])\n",
    "        # conf のサイズは、torch.Size([batch_num, 8732, 21])\n",
    "        loc = loc.view(loc.size(0), -1, 4)\n",
    "        conf = conf.view(conf.size(0), -1, self.num_classes)\n",
    "\n",
    "        # 最後に出力する\n",
    "        output = (loc, conf, self.dbox_list)\n",
    "\n",
    "        if self.phase == \"inference\": # 推論時\n",
    "            # クラス「Detect」の forward を実行\n",
    "            # 返り値のサイズは torch.Size([batch_num, 21, 200, 5])\n",
    "            return self.detect(output[0], output[1], output[2])\n",
    "        else: # 学習時\n",
    "            # 返り値は (loc, conf, dbox_list) のタプル\n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['jupyter', 'nbconvert', '--to', 'python', '2-5_SSD_Model_Forward.ipynb'], returncode=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "subprocess.run(['jupyter', 'nbconvert', '--to', 'python', '2-5_SSD_Model_Forward.ipynb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
