{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-1 セマンティックセグメンテーションとは\n",
    "\n",
    "## セマンティックセグメンテーションの概要\n",
    "セマンティックセグメンテーションは，1枚の画像中に含まれる複数の物体に対して，物体領域と物体名をピクセルレベルで付与するタスクである．\n",
    "以下にセマンティックセグメンテーションの結果の一例を示す．\n",
    "\n",
    "<img src=\"../image/p131.png\">\n",
    "\n",
    "セマンティックセグメンテーションは，製造業における製品の損傷部分の検出や医療画像診断，自動運転など様々な分野に応用されている．\n",
    "\n",
    "## セマンティックセグメンテーションの入出力\n",
    "セマンティックセグメンテーションの入力は画像，出力は各ピクセルが属するクラスのラベルとなる．\n",
    "このアウトプットを画像にすると，上の図のようになる．\n",
    "通常，画像のデータは RGB の3チャネルの配列で表される．\n",
    "しかし，セマンティックセグメンテーションの出力はチャネル数が1で，各ピクセルにはラベル情報が格納されているため，カラーパレット形式と呼ばれる形式で画像を表現する．  \n",
    "カラーパレット形式では，0から順に各数字に対して対応する RGB の値を格納しておき，それを元に画像を表示している．\n",
    "これによって，1チャネルで RGB を表現することが可能となる．\n",
    "\n",
    "## VOC データセット\n",
    "この章でも前章と同様，PASCAL VOC2012 データセットを用いる．\n",
    "セマンティックセグメンテーション用のアノテーションが用意されている訓練データ1,464枚，検証データ1,449枚（クラス数は21）のみを用いる．\n",
    "\n",
    "## PSPNet による物体検出の流れ\n",
    "PSPNet（Pyramid Scene Parsing Network）は次のような流れでセマンティックセグメンテーションを行う．\n",
    "\n",
    "### Step1. 前処理\n",
    "画像サイズをリサイズし，色情報の標準化を行う．\n",
    "リサイズ後の大きさは任意だが，ここでは 475 x 475 とする．\n",
    "### Step2. PSPNet への入力\n",
    "前のステップで処理した画像をネットワークに入力する．\n",
    "PSPNet からの出力は 21 x 475 x 475（クラス数 x 高さ x 幅）の配列である．\n",
    "出力配列の各値は各ピクセルが各クラスに属する確信度に対応する．\n",
    "### Step3. 確信度最大のクラスを抽出\n",
    "出力の各ピクセルについて，確信度が最大となるクラスを求める．\n",
    "このピクセルごとの確信度最大クラスがセマンティックセグメンテーションの出力となる．\n",
    "### Step4. 前処理\n",
    "セマンティックセグメンテーションの出力を元の画像と同じ大きさにリサイズする．\n",
    "\n",
    "<img src=\"../image/p133.png\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
