{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4-3 OpenPose のネットワーク構成と実装\n",
    "\n",
    "## OpenPose を構成するモジュール\n",
    "以下に OpenPose のモジュール構成を示す．\n",
    "\n",
    "<img src=\"../image/p208.png\">\n",
    "\n",
    "OpenPose は7個のモジュールから構成される．\n",
    "画像の特徴量を抽出する Feature モジュールと，heatmaps と PAFs を出力する Stage1 ~ Stage6 の6個の Stage モジュールを用意する．  \n",
    "前処理された画像データは最初に Feature モジュールに入力され，128チャネルの特徴量に変換される．\n",
    "Feature モジュールでは VGG-19 を使用し，出力される画像サイズは 1/8 になる．\n",
    "そのため，Feature モジュールの出力は 128×46×46 となる．  \n",
    "Feature モジュールの出力は，その後 Stage1 から Stage6 へと送られる．\n",
    "Stage1 では Feature モジュールの出力を2つのサブネットワークに入力する．\n",
    "それぞれのサブネットワークを block1_1 と block1_2 とする．\n",
    "前者は 38×46×46 サイズの PAFsを，後者は 19×46×46 サイズの heatmaps を出力する．  \n",
    "簡単に姿勢推定をするだけなら Stage1 の出力を用いればよいが，これだけでは十分な精度が得られないため，Stage1 と Feature モジュールの出力を使ってさらに精度の良い姿勢推定を行う．  \n",
    "Stage1 と Feature モジュールの出力を全てチャネル方向に結合させ，185×46×46 のテンソルとして Stage2 の block2_1 と block2_2 に入力する．\n",
    "Stage2 でも同様に PAFs と Heatmaps を出力する．\n",
    "これによって，Stage1 より精度の高い姿勢推定の結果が得られる．  \n",
    "同様に前段の Stage モジュールの出力（38×46×46，19×46×46）と Feature モジュールの出力（128×46×46）をチャネル方向に結合したものを，次段の Stage モジュールに入力することを繰り返し，最終的に Stage6 の出力する PAFs と heatmaps を使って姿勢推定を行う．\n",
    "\n",
    "## OpenPoseNet の実装\n",
    "これまで通り，コンストラクタで各モジュールを生成し，順伝播関数 forward を定義する．\n",
    "OpenPose のネットワークの学習を行う際には，各 Stage の PAFs と heatmaps に対して教師データのものとの損失値を計算する．\n",
    "最終的な forward 関数の出力は Stage6 の PAFs と heatmaps，及び各 Stage モジュールの PAFs と heatmaps を辞書型変数にまとめた saved_for_lossとなる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class OpenPoseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OpenPoseNet, self).__init__()\n",
    "        \n",
    "        # Feature モジュール\n",
    "        self.model0 = OpenPose_Feature()\n",
    "        \n",
    "        # Stage モジュール\n",
    "        # PAFs (Part Affinity Fields) 側\n",
    "        self.model1_1 = make_OpenPose_block(\"block1_1\")\n",
    "        self.model2_1 = make_OpenPose_block(\"block2_1\")\n",
    "        self.model3_1 = make_OpenPose_block(\"block3_1\")\n",
    "        self.model4_1 = make_OpenPose_block(\"block4_1\")\n",
    "        self.model5_1 = make_OpenPose_block(\"block5_1\")\n",
    "        self.model6_1 = make_OpenPose_block(\"block6_1\")\n",
    "        \n",
    "        # confidence heatmap 側\n",
    "        self.model1_2= make_OpenPose_block(\"block1_2\")\n",
    "        self.model2_2= make_OpenPose_block(\"block2_2\")\n",
    "        self.model3_2= make_OpenPose_block(\"block3_2\")\n",
    "        self.model4_2= make_OpenPose_block(\"block4_2\")\n",
    "        self.model5_2= make_OpenPose_block(\"block5_2\")\n",
    "        self.model6_2= make_OpenPose_block(\"block6_2\")\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        ''' 順伝播関数の定義 '''\n",
    "        \n",
    "        # Feature モジュール\n",
    "        out1 = self.model0(x)\n",
    "        \n",
    "        # Stage1\n",
    "        out1_1 = self.model1_1(out1) # PAFs\n",
    "        out1_2 = self.model1_2(out1) # confidence heatmaps\n",
    "        \n",
    "        # Stage2\n",
    "        out2 = torch.cat([out1_1, out1_2, out1], 1) # チャネルの次元で結合\n",
    "        out2_1 = self.model2_1(out2) # PAFs\n",
    "        out2_2 = self.model2_2(out2) # confidence heatmaps\n",
    "        \n",
    "        # Stage3\n",
    "        out3 = torch.cat([out2_1, out2_2, out1], 1) # チャネルの次元で結合\n",
    "        out3_1 = self.model3_1(out3) # PAFs\n",
    "        out3_2 = self.model3_2(out3) # confidence heatmaps\n",
    "        \n",
    "        # Stage4\n",
    "        out4 = torch.cat([out3_1, out3_2, out1], 1) # チャネルの次元で結合\n",
    "        out4_1 = self.model4_1(out4) # PAFs\n",
    "        out4_2 = self.model4_2(out4) # confidence heatmaps\n",
    "        \n",
    "        # Stage5\n",
    "        out5 = torch.cat([out4_1, out4_2, out1], 1) # チャネルの次元で結合\n",
    "        out5_1 = self.model5_1(out5) # PAFs\n",
    "        out5_2 = self.model5_2(out5) # confidence heatmaps\n",
    "        \n",
    "        # Stage6\n",
    "        out6 = torch.cat([out5_1, out5_2, out1], 1) # チャネルの次元で結合\n",
    "        out6_1 = self.model6_1(out6) # PAFs\n",
    "        out6_2 = self.model6_2(out6) # confidence heatmaps\n",
    "        \n",
    "        # 損失の計算用に各 Stage の結果を格納\n",
    "        saved_for_loss = []\n",
    "        saved_for_loss.append(out1_1)\n",
    "        saved_for_loss.append(out1_2)\n",
    "        saved_for_loss.append(out2_1)\n",
    "        saved_for_loss.append(out2_2)\n",
    "        saved_for_loss.append(out3_1)\n",
    "        saved_for_loss.append(out3_2)\n",
    "        saved_for_loss.append(out4_1)\n",
    "        saved_for_loss.append(out4_2)\n",
    "        saved_for_loss.append(out5_1)\n",
    "        saved_for_loss.append(out5_2)\n",
    "        saved_for_loss.append(out6_1)\n",
    "        saved_for_loss.append(out6_2)\n",
    "        \n",
    "        # 最終的な PAFs の out6_1 と confidence heatmap の out6_2，\n",
    "        # 損失計算用に各ステージでの PAFs と heatmap を格納した saved_for_loss を出力\n",
    "        # out6_1:torch.Size([minibatch, 38, 46, 46])\n",
    "        # out6_2:torch.Size([minibatch, 19, 46, 46])\n",
    "        # saved_for_loss:[out1_1, out_1_2, ・・・, out6_2]\n",
    "        \n",
    "        return (out6_1, out6_2), saved_for_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
