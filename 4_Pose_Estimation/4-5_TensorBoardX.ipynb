{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4-5 TensorBoardX を使用したネットワークの可視化手法\n",
    "\n",
    "## TensorBoardX\n",
    "TensorBoardX は TensorFlow の可視化ライブラリ TensorBoard を PyTorch から使用できるようにしたサードパーティ製のパッケージである．\n",
    "基本的には PyTorch のモデルをニューラルネットワークの共通フォーマットである ONNX（オニキス，Open Neural Network Exchange）形式に変換し，TensorBoard に流し込んでいる．\n",
    "このライブラリを使うために TensorFlow と TensorBoardX をインストールする．\n",
    "\n",
    "## graph ファイルの作成\n",
    "可視化したいネットワークモデルのファイル（graph ファイル）を作成する．\n",
    "はじめに，前節までに作成した OpenPose のネットワークモデルのインスタンスを生成する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenPoseNet(\n",
       "  (model0): OpenPose_Feature(\n",
       "    (model): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): ReLU(inplace=True)\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (13): ReLU(inplace=True)\n",
       "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): ReLU(inplace=True)\n",
       "      (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (17): ReLU(inplace=True)\n",
       "      (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (20): ReLU(inplace=True)\n",
       "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (22): ReLU(inplace=True)\n",
       "      (23): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (24): ReLU(inplace=True)\n",
       "      (25): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (26): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (model1_1): Sequential(\n",
       "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(512, 38, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (model2_1): Sequential(\n",
       "    (0): Conv2d(185, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(128, 38, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (model3_1): Sequential(\n",
       "    (0): Conv2d(185, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(128, 38, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (model4_1): Sequential(\n",
       "    (0): Conv2d(185, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(128, 38, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (model5_1): Sequential(\n",
       "    (0): Conv2d(185, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(128, 38, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (model6_1): Sequential(\n",
       "    (0): Conv2d(185, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(128, 38, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (model1_2): Sequential(\n",
       "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(512, 19, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (model2_2): Sequential(\n",
       "    (0): Conv2d(185, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(128, 19, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (model3_2): Sequential(\n",
       "    (0): Conv2d(185, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(128, 19, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (model4_2): Sequential(\n",
       "    (0): Conv2d(185, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(128, 19, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (model5_2): Sequential(\n",
       "    (0): Conv2d(185, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(128, 19, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (model6_2): Sequential(\n",
       "    (0): Conv2d(185, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(128, 19, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.openpose_net import OpenPoseNet\n",
    "\n",
    "net = OpenPoseNet()\n",
    "net.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に graph ファイルを保存するために Write クラスを用意する．\n",
    "SummaryWriter をインポートし，インスタンス writer を生成する．  \n",
    "以下のコードでは，tbx フォルダ（自動的に生成）に graph ファイルが保存される．\n",
    "次にモデル net に入力するダミーの入力データとして，テンソル dummy_img を作成する．\n",
    "ダミーの入力データが作成できたら writer.add_graph() コマンドを利用し，net と dummy_img を writer で保存し，writer を close しておく．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only tensors or tuples of tensors can be output from traced functions (getOutput at /pytorch/torch/csrc/jit/tracer.cpp:208)\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x33 (0x7f9b7a617273 in /home/yuko/.python-venv/lib/python3.7/site-packages/torch/lib/libc10.so)\n",
      "frame #1: torch::jit::tracer::TracingState::getOutput(c10::IValue const&) + 0x3e8 (0x7f9b7e86e228 in /home/yuko/.python-venv/lib/python3.7/site-packages/torch/lib/libtorch.so)\n",
      "frame #2: torch::jit::tracer::TracingState::getOutput(c10::IValue const&) + 0x10f (0x7f9b7e86df4f in /home/yuko/.python-venv/lib/python3.7/site-packages/torch/lib/libtorch.so)\n",
      "frame #3: torch::jit::tracer::exit(std::vector<c10::IValue, std::allocator<c10::IValue> > const&) + 0x3c (0x7f9b7e86e55c in /home/yuko/.python-venv/lib/python3.7/site-packages/torch/lib/libtorch.so)\n",
      "frame #4: <unknown function> + 0x4bf042 (0x7f9bc4970042 in /home/yuko/.python-venv/lib/python3.7/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #5: <unknown function> + 0x4d30f1 (0x7f9bc49840f1 in /home/yuko/.python-venv/lib/python3.7/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #6: <unknown function> + 0x1d3ab4 (0x7f9bc4684ab4 in /home/yuko/.python-venv/lib/python3.7/site-packages/torch/lib/libtorch_python.so)\n",
      "frame #7: _PyMethodDef_RawFastCallKeywords + 0x224 (0x5b0554 in /home/yuko/.python-venv/bin/python3.7)\n",
      "frame #8: _PyObject_FastCallKeywords + 0x6f0 (0x5b1f10 in /home/yuko/.python-venv/bin/python3.7)\n",
      "frame #9: /home/yuko/.python-venv/bin/python3.7() [0x5cc8f1]\n",
      "frame #10: _PyEval_EvalFrameDefault + 0x4759 (0x51add9 in /home/yuko/.python-venv/bin/python3.7)\n",
      "frame #11: _PyEval_EvalCodeWithName + 0x252 (0x5cd202 in /home/yuko/.python-venv/bin/python3.7)\n",
      "frame #12: _PyFunction_FastCallKeywords + 0x482 (0x5b11a2 in /home/yuko/.python-venv/bin/python3.7)\n",
      "frame #13: _PyEval_EvalFrameDefault + 0x51a (0x516b9a in /home/yuko/.python-venv/bin/python3.7)\n",
      "frame #14: _PyEval_EvalCodeWithName + 0x252 (0x5cd202 in /home/yuko/.python-venv/bin/python3.7)\n",
      "frame #15: _PyFunction_FastCallKeywords + 0x482 (0x5b11a2 in /home/yuko/.python-venv/bin/python3.7)\n",
      "frame #16: /home/yuko/.python-venv/bin/python3.7() [0x5cc6ea]\n",
      "frame #17: _PyEval_EvalFrameDefault + 0x4759 (0x51add9 in /home/yuko/.python-venv/bin/python3.7)\n",
      "frame #18: _PyEval_EvalCodeWithName + 0x252 (0x5cd202 in /home/yuko/.python-venv/bin/python3.7)\n",
      "frame #19: _PyFunction_FastCallDict + 0x367 (0x5b2437 in /home/yuko/.python-venv/bin/python3.7)\n",
      "frame #20: _PyEval_EvalFrameDefault + 0x19c1 (0x518041 in /home/yuko/.python-venv/bin/python3.7)\n",
      "frame #21: _PyEval_EvalCodeWithName + 0x252 (0x5cd202 in /home/yuko/.python-venv/bin/python3.7)\n",
      "frame #22: _PyFunction_FastCallKeywords + 0x482 (0x5b11a2 in /home/yuko/.python-venv/bin/python3.7)\n",
      "frame #23: _PyEval_EvalFrameDefault + 0x6ea (0x516d6a in /home/yuko/.python-venv/bin/python3.7)\n",
      "frame #24: _PyEval_EvalCodeWithName + 0x252 (0x5cd202 in /home/yuko/.python-venv/bin/python3.7)\n",
      "frame #25: /home/yuko/.python-venv/bin/python3.7() [0x521421]\n",
      "frame #26: _PyMethodDef_RawFastCallKeywords + 0x1b3 (0x5b04e3 in /home/yuko/.python-venv/bin/python3.7)\n",
      "frame #27: _PyEval_EvalFrameDefault + 0x4603 (0x51ac83 in /home/yuko/.python-venv/bin/python3.7)\n",
      "frame #28: /home/yuko/.python-venv/bin/python3.7() [0x4d1c46]\n",
      "frame #29: _PyEval_EvalFrameDefault + 0x1bcc (0x51824c in /home/yuko/.python-venv/bin/python3.7)\n",
      "frame #30: /home/yuko/.python-venv/bin/python3.7() [0x4d1c46]\n",
      "frame #31: _PyEval_EvalFrameDefault + 0x1bcc (0x51824c in /home/yuko/.python-venv/bin/python3.7)\n",
      "frame #32: /home/yuko/.python-venv/bin/python3.7() [0x4d1c46]\n",
      "frame #33: _PyMethodDescr_FastCallKeywords + 0x151 (0x4d38b1 in /home/yuko/.python-venv/bin/python3.7)\n",
      "frame #34: _PyEval_EvalFrameDefault + 0x4947 (0x51afc7 in /home/yuko/.python-venv/bin/python3.7)\n",
      "frame #35: _PyFunction_FastCallKeywords + 0x18c (0x5b0eac in /home/yuko/.python-venv/bin/python3.7)\n",
      "frame #36: _PyEval_EvalFrameDefault + 0x51a (0x516b9a in /home/yuko/.python-venv/bin/python3.7)\n",
      "frame #37: _PyFunction_FastCallKeywords + 0x18c (0x5b0eac in /home/yuko/.python-venv/bin/python3.7)\n",
      "frame #38: _PyEval_EvalFrameDefault + 0x6ea (0x516d6a in /home/yuko/.python-venv/bin/python3.7)\n",
      "frame #39: _PyEval_EvalCodeWithName + 0x252 (0x5cd202 in /home/yuko/.python-venv/bin/python3.7)\n",
      "frame #40: _PyFunction_FastCallDict + 0x367 (0x5b2437 in /home/yuko/.python-venv/bin/python3.7)\n",
      "frame #41: /home/yuko/.python-venv/bin/python3.7() [0x4d35c2]\n",
      "frame #42: PyObject_Call + 0x56 (0x5b4266 in /home/yuko/.python-venv/bin/python3.7)\n",
      "frame #43: _PyEval_EvalFrameDefault + 0x19c1 (0x518041 in /home/yuko/.python-venv/bin/python3.7)\n",
      "frame #44: _PyEval_EvalCodeWithName + 0x252 (0x5cd202 in /home/yuko/.python-venv/bin/python3.7)\n",
      "frame #45: _PyFunction_FastCallKeywords + 0x482 (0x5b11a2 in /home/yuko/.python-venv/bin/python3.7)\n",
      "frame #46: /home/yuko/.python-venv/bin/python3.7() [0x5cc6ea]\n",
      "frame #47: _PyEval_EvalFrameDefault + 0x141e (0x517a9e in /home/yuko/.python-venv/bin/python3.7)\n",
      "frame #48: /home/yuko/.python-venv/bin/python3.7() [0x4d2085]\n",
      "frame #49: /home/yuko/.python-venv/bin/python3.7() [0x51ecd6]\n",
      "frame #50: _PyMethodDef_RawFastCallKeywords + 0x1b3 (0x5b04e3 in /home/yuko/.python-venv/bin/python3.7)\n",
      "frame #51: _PyEval_EvalFrameDefault + 0x4603 (0x51ac83 in /home/yuko/.python-venv/bin/python3.7)\n",
      "frame #52: _PyEval_EvalCodeWithName + 0x252 (0x5cd202 in /home/yuko/.python-venv/bin/python3.7)\n",
      "frame #53: _PyFunction_FastCallKeywords + 0x482 (0x5b11a2 in /home/yuko/.python-venv/bin/python3.7)\n",
      "frame #54: _PyEval_EvalFrameDefault + 0x6ea (0x516d6a in /home/yuko/.python-venv/bin/python3.7)\n",
      "frame #55: /home/yuko/.python-venv/bin/python3.7() [0x4d2085]\n",
      "frame #56: /home/yuko/.python-venv/bin/python3.7() [0x51ecd6]\n",
      "frame #57: _PyMethodDef_RawFastCallKeywords + 0x1b3 (0x5b04e3 in /home/yuko/.python-venv/bin/python3.7)\n",
      "frame #58: _PyEval_EvalFrameDefault + 0x4603 (0x51ac83 in /home/yuko/.python-venv/bin/python3.7)\n",
      "frame #59: _PyEval_EvalCodeWithName + 0x252 (0x5cd202 in /home/yuko/.python-venv/bin/python3.7)\n",
      "frame #60: _PyFunction_FastCallKeywords + 0x482 (0x5b11a2 in /home/yuko/.python-venv/bin/python3.7)\n",
      "frame #61: _PyEval_EvalFrameDefault + 0x51a (0x516b9a in /home/yuko/.python-venv/bin/python3.7)\n",
      "frame #62: /home/yuko/.python-venv/bin/python3.7() [0x4d2085]\n",
      "frame #63: /home/yuko/.python-venv/bin/python3.7() [0x51ecd6]\n",
      "\n",
      "Error occurs, No graph saved\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'GraphDef' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d0a0b848025b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# 4. OpenPoseのインスタンスnetに対して、ダミーデータである\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# dummy_imgを流したときのgraphをwriterに保存させます\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdummy_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.python-venv/lib/python3.7/site-packages/tensorboardX/writer.py\u001b[0m in \u001b[0;36madd_graph\u001b[0;34m(self, model, input_to_model, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    736\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'add_graph() only supports PyTorch v0.2.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 738\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_file_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_to_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m             \u001b[0;31m# Caffe2 models do not have the 'forward' method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.python-venv/lib/python3.7/site-packages/tensorboardX/writer.py\u001b[0m in \u001b[0;36madd_graph\u001b[0;34m(self, graph_profile, walltime)\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0mwalltime\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mfrom\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mseconds\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \"\"\"\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_profile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0mstepstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_profile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevent_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'GraphDef' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# 1. tensorboardXの保存クラスを呼び出します\n",
    "import torch\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "# 2. フォルダ「tbX」に保存させるwriterを用意します\n",
    "# フォルダ「tbX」はなければ自動で作成されます\n",
    "writer = SummaryWriter(\"./tbX/\")\n",
    "\n",
    "\n",
    "# 3. ネットワークに流し込むダミーデータを作成します\n",
    "batch_size = 4\n",
    "dummy_img = torch.rand(batch_size, 3, 368, 368)\n",
    "\n",
    "# 4. OpenPoseのインスタンスnetに対して、ダミーデータである\n",
    "# dummy_imgを流したときのgraphをwriterに保存させます\n",
    "writer.add_graph(net, (dummy_img, ))\n",
    "writer.close()\n",
    "\n",
    "\n",
    "# 5. コマンドプロンプトを開き、フォルダ「tbX」がある\n",
    "# フォルダ「4_pose_estimation」まで移動して、\n",
    "# 以下のコマンドを実行します\n",
    "\n",
    "# tensorboard --logdir=\"./tbX/\"\n",
    "\n",
    "# その後、http://localhost:6006\n",
    "# にアクセスします"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "※　TypeError: 'GraphDef' object is not subscriptable　で動作確認できず"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
